{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import hdbscan\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import numpy as np\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    6000\n",
      "1.0    6000\n",
      "Name: target, dtype: int64\n",
      "Number of Observations: 12000\n"
     ]
    }
   ],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "adult = fetch_ucirepo(id=2)   #adult dataset \n",
    "X = adult.data.features \n",
    "y = adult.data.targets \n",
    "\n",
    "df = X.copy()\n",
    "df['y'] = y\n",
    " \n",
    "df=df.dropna()\n",
    "\n",
    "df['target'] = df['y'].map({'<=50K': 0, '<=50K.': 0, '>50K': 1, '>50K.': 1})\n",
    "df = df.drop('y', axis=1)\n",
    "\n",
    "df_num = df[['age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week', 'target']]\n",
    "\n",
    "def sample_from_group(group):\n",
    "    return group.sample(min(len(group), 6000), random_state=42)\n",
    "\n",
    "sampled_df = df_num.groupby('target', group_keys=False).apply(sample_from_group)\n",
    "\n",
    "sampled_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "\n",
    "# MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_num_scaled = scaler.fit_transform(sampled_df)\n",
    "df_num = pd.DataFrame(df_num_scaled, columns=df_num.columns)\n",
    "\n",
    "target_counts = df_num['target'].value_counts()\n",
    "print(target_counts)\n",
    "\n",
    "num_observations = df_num.shape[0]\n",
    "print(\"Number of Observations:\", num_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in df_subset_1: 3000\n",
      "Number of rows in df_subset_2: 9000\n"
     ]
    }
   ],
   "source": [
    "# Randomly select 3000 rows\n",
    "df_X_test = df_num.sample(n=3000, random_state=42)\n",
    "\n",
    "# Remove the selected rows from the original DataFrame to create the second subset\n",
    "df_subset_2 = df_num.drop(df_X_test.index)\n",
    "\n",
    "# df_subset_1 contains 3000 randomly selected observations for test set\n",
    "# and df_subset_2 contains the rest of the observations from the original subset for train and val\n",
    "\n",
    "print(\"Number of rows in df_subset_1:\", len(df_X_test))\n",
    "print(\"Number of rows in df_subset_2:\", len(df_subset_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_num = df_subset_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "df_X_test1 = df_X_test.drop('target', axis=1)\n",
    "df_y_test1 = df_X_test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "X = df_num.drop('target', axis=1)\n",
    "y = df_num['target']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7026666666666667\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353\n",
      "316\n"
     ]
    }
   ],
   "source": [
    "# observations that was misclassified from val set\n",
    "\n",
    "error_mask = y_test != y_pred\n",
    "error_features = X_test[error_mask]\n",
    "error_points = y_test[error_mask]\n",
    "\n",
    "errors_0 = error_features[y_test[error_mask] == 0]\n",
    "errors_1 = error_features[y_test[error_mask] == 1]\n",
    "errors_0_y = error_points[y_test[error_mask] == 0]\n",
    "errors_1_y = error_points[y_test[error_mask] == 1]\n",
    "\n",
    "print(len(errors_0))\n",
    "print(len(errors_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          age    fnlwgt  capital-gain  capital-loss  hours-per-week\n",
      "min  0.082192  0.011991      0.000000      0.000000        0.010204\n",
      "max  0.739726  0.649530      0.068491      0.459366        0.887755\n",
      "          age    fnlwgt  capital-gain  capital-loss  hours-per-week\n",
      "min  0.082192  0.000000       0.00000      0.000000        0.061224\n",
      "max  0.821918  0.474041       0.04386      0.518365        0.908163\n"
     ]
    }
   ],
   "source": [
    "print(errors_0.describe().loc[['min', 'max']])\n",
    "print(errors_1.describe().loc[['min', 'max']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           age    fnlwgt  capital-gain  capital-loss  hours-per-week  target\n",
      "1     0.301370  0.254985           0.0       0.00000        0.397959     0.0\n",
      "6     0.095890  0.155360           0.0       0.00000        0.295918     0.0\n",
      "9     0.328767  0.036319           0.0       0.00000        0.397959     0.0\n",
      "11    0.178082  0.072266           0.0       0.00000        0.602041     0.0\n",
      "16    0.273973  0.021040           0.0       0.00000        0.397959     0.0\n",
      "...        ...       ...           ...           ...             ...     ...\n",
      "5990  0.547945  0.134525           0.0       0.00000        0.397959     0.0\n",
      "5992  0.671233  0.074280           0.0       0.00000        0.500000     0.0\n",
      "5994  0.438356  0.087531           0.0       0.00000        0.448980     0.0\n",
      "5996  0.561644  0.202261           0.0       0.00000        0.397959     0.0\n",
      "5997  0.219178  0.071503           0.0       0.20202        0.397959     0.0\n",
      "\n",
      "[3505 rows x 6 columns]\n",
      "            age    fnlwgt  capital-gain  capital-loss  hours-per-week  target\n",
      "6000   0.260274  0.029988           0.0      0.000000        0.500000     1.0\n",
      "6001   0.219178  0.136390           0.0      0.000000        0.397959     1.0\n",
      "6002   0.219178  0.104692           0.0      0.000000        0.846939     1.0\n",
      "6003   0.684932  0.148413           0.0      0.000000        0.397959     1.0\n",
      "6004   0.465753  0.099911           0.0      0.000000        0.397959     1.0\n",
      "...         ...       ...           ...           ...             ...     ...\n",
      "11990  0.397260  0.157174           0.0      0.000000        0.602041     1.0\n",
      "11992  0.328767  0.346551           0.0      0.340909        0.500000     1.0\n",
      "11993  0.260274  0.015882           0.0      0.453857        0.397959     1.0\n",
      "11996  0.315068  0.162532           0.0      0.000000        0.438776     1.0\n",
      "11999  0.397260  0.065043           0.0      0.000000        0.397959     1.0\n",
      "\n",
      "[3465 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ranges for each feature for class 0\n",
    "feature_ranges_0 = {\n",
    "    'age': (0.082192, 0.739726),\n",
    "    'fnlwgt': (0.011991, 0.649530),\n",
    "    'capital-gain': (0.0, 0.068491),\n",
    "    'capital-loss': (0.0, 0.459366),\n",
    "    'hours-per-week': (0.010204,  0.887755)\n",
    "}\n",
    "\n",
    "# Ranges for each feature for class 1\n",
    "feature_ranges_1 = {\n",
    "    'age': (0.082192, 0.821918),\n",
    "    'fnlwgt': (0.0, 0.474041),\n",
    "    'capital-gain': (0.0,  0.04386 ),\n",
    "    'capital-loss': (0.0, 0.518365),\n",
    "    'hours-per-week': (0.061224, 0.908163)\n",
    "}\n",
    "\n",
    "# Filter class 0\n",
    "filtered_class_0_with_y = df_num[(df_num['target'] == 0) &\n",
    "    (df_num['age'].between(feature_ranges_0['age'][0], feature_ranges_0['age'][1])) &\n",
    "    (df_num['fnlwgt'].between(feature_ranges_0['fnlwgt'][0], feature_ranges_0['fnlwgt'][1])) &\n",
    "    (df_num['capital-gain'].between(feature_ranges_0['capital-gain'][0], feature_ranges_0['capital-gain'][1])) &\n",
    "    (df_num['capital-loss'].between(feature_ranges_0['capital-loss'][0], feature_ranges_0['capital-loss'][1])) &\n",
    "    (df_num['hours-per-week'].between(feature_ranges_0['hours-per-week'][0], feature_ranges_0['hours-per-week'][1]))\n",
    "]\n",
    "\n",
    "# Filter class 1\n",
    "filtered_class_1_with_y = df_num[(df_num['target'] == 1) &\n",
    "    (df_num['age'].between(feature_ranges_1['age'][0], feature_ranges_1['age'][1])) &\n",
    "    (df_num['fnlwgt'].between(feature_ranges_1['fnlwgt'][0], feature_ranges_1['fnlwgt'][1])) &\n",
    "    (df_num['capital-gain'].between(feature_ranges_1['capital-gain'][0], feature_ranges_1['capital-gain'][1])) &\n",
    "    (df_num['capital-loss'].between(feature_ranges_1['capital-loss'][0], feature_ranges_1['capital-loss'][1])) &\n",
    "    (df_num['hours-per-week'].between(feature_ranges_1['hours-per-week'][0], feature_ranges_1['hours-per-week'][1]))\n",
    "]\n",
    "\n",
    "\n",
    "print(filtered_class_0_with_y)\n",
    "print(filtered_class_1_with_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of densest points in class 0: 108\n",
      "Number of densest points in class 1: 92\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Concatenate errors and their corresponding labels for each class\n",
    "errors_all = pd.concat([errors_0, errors_1])\n",
    "errors_all_y = pd.concat([errors_0_y, errors_1_y])\n",
    "\n",
    "# Calculate density for each data point\n",
    "k_neighbors = 10  \n",
    "nn = NearestNeighbors(n_neighbors=k_neighbors)\n",
    "nn.fit(errors_all)\n",
    "distances, _ = nn.kneighbors(errors_all)\n",
    "\n",
    "# Calculate density as the inverse of the mean distance to the k nearest neighbors\n",
    "density = 1.0 / (distances.mean(axis=1) + 1e-6)  # Add a small value to avoid division by zero\n",
    "\n",
    "# Sort data points by density\n",
    "sorted_indices = np.argsort(density)\n",
    "\n",
    "# Select the top 30 % densest data points\n",
    "densest_points_indices = sorted_indices[-int(len(errors_all) * 0.3):]\n",
    "\n",
    "# Extract the densest 30 % points and their corresponding labels\n",
    "densest_points = errors_all.iloc[densest_points_indices]\n",
    "densest_points_y = errors_all_y.iloc[densest_points_indices]\n",
    "\n",
    "# Print the lengths of densest points for each class\n",
    "print(\"Number of densest points in class 0:\", (densest_points_y == 0).sum())\n",
    "print(\"Number of densest points in class 1:\", (densest_points_y == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ranges of the densest 50% points for class 0:\n",
      "          age    fnlwgt  capital-gain  capital-loss  hours-per-week\n",
      "min  0.136986  0.028452           0.0           0.0        0.397959\n",
      "max  0.561644  0.254985           0.0           0.0        0.408163\n",
      "\n",
      "Ranges of the densest 50% points for class 1:\n",
      "          age    fnlwgt  capital-gain  capital-loss  hours-per-week\n",
      "min  0.123288  0.043407           0.0           0.0        0.377551\n",
      "max  0.561644  0.256510           0.0           0.0        0.397959\n"
     ]
    }
   ],
   "source": [
    "# Calculate the minimum and maximum values for each feature in the densest 30 % points for class 0\n",
    "ranges_densest_points_class_0 = densest_points[densest_points_y == 0].agg(['min', 'max'])\n",
    "\n",
    "# Calculate the minimum and maximum values for each feature in the densest 30 % points for class 1\n",
    "ranges_densest_points_class_1 = densest_points[densest_points_y == 1].agg(['min', 'max'])\n",
    "\n",
    "print(\"Ranges of the densest 50% points for class 0:\")\n",
    "print(ranges_densest_points_class_0)\n",
    "\n",
    "print(\"\\nRanges of the densest 50% points for class 1:\")\n",
    "print(ranges_densest_points_class_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           age    fnlwgt  capital-gain  capital-loss  hours-per-week  target\n",
      "1     0.301370  0.254985           0.0           0.0        0.397959     0.0\n",
      "9     0.328767  0.036319           0.0           0.0        0.397959     0.0\n",
      "18    0.178082  0.038210           0.0           0.0        0.397959     0.0\n",
      "34    0.260274  0.085881           0.0           0.0        0.397959     0.0\n",
      "40    0.150685  0.111286           0.0           0.0        0.397959     0.0\n",
      "...        ...       ...           ...           ...             ...     ...\n",
      "5985  0.534247  0.096034           0.0           0.0        0.397959     0.0\n",
      "5986  0.506849  0.092272           0.0           0.0        0.397959     0.0\n",
      "5987  0.328767  0.177850           0.0           0.0        0.397959     0.0\n",
      "5990  0.547945  0.134525           0.0           0.0        0.397959     0.0\n",
      "5996  0.561644  0.202261           0.0           0.0        0.397959     0.0\n",
      "\n",
      "[1157 rows x 6 columns]\n",
      "            age    fnlwgt  capital-gain  capital-loss  hours-per-week  target\n",
      "6001   0.219178  0.136390           0.0           0.0        0.397959     1.0\n",
      "6004   0.465753  0.099911           0.0           0.0        0.397959     1.0\n",
      "6006   0.205479  0.164746           0.0           0.0        0.377551     1.0\n",
      "6010   0.328767  0.141049           0.0           0.0        0.397959     1.0\n",
      "6011   0.191781  0.140145           0.0           0.0        0.397959     1.0\n",
      "...         ...       ...           ...           ...             ...     ...\n",
      "11980  0.328767  0.091684           0.0           0.0        0.397959     1.0\n",
      "11982  0.424658  0.078216           0.0           0.0        0.397959     1.0\n",
      "11984  0.273973  0.076904           0.0           0.0        0.397959     1.0\n",
      "11986  0.410959  0.071326           0.0           0.0        0.397959     1.0\n",
      "11999  0.397260  0.065043           0.0           0.0        0.397959     1.0\n",
      "\n",
      "[979 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ranges for each feature for class 0\n",
    "feature_ranges_0 = {\n",
    "    'age': (0.136986, 0.561645),\n",
    "    'fnlwgt': (0.028452, 0.2550),\n",
    "    'capital-gain': (0.0, 0.0),\n",
    "    'capital-loss': (0.0, 0.0),\n",
    "    'hours-per-week': (0.397959, 0.408164)\n",
    "}\n",
    "\n",
    "# Ranges for each feature for class 1\n",
    "feature_ranges_1 = {\n",
    "    'age': (0.123288, 0.561645),\n",
    "    'fnlwgt': (0.043407, 0.256510),\n",
    "    'capital-gain': (0.0, 0.0),\n",
    "    'capital-loss': (0.0, 0.0),\n",
    "    'hours-per-week': (0.377550, 0.39796)\n",
    "}\n",
    "\n",
    "# Filter class 0\n",
    "filtered_class_0_with_y = df_num[(df_num['target'] == 0) &\n",
    "    (df_num['age'].between(feature_ranges_0['age'][0], feature_ranges_0['age'][1])) &\n",
    "    (df_num['fnlwgt'].between(feature_ranges_0['fnlwgt'][0], feature_ranges_0['fnlwgt'][1])) &\n",
    "    (df_num['capital-gain'].between(feature_ranges_0['capital-gain'][0], feature_ranges_0['capital-gain'][1])) &\n",
    "    (df_num['capital-loss'].between(feature_ranges_0['capital-loss'][0], feature_ranges_0['capital-loss'][1])) &\n",
    "    (df_num['hours-per-week'].between(feature_ranges_0['hours-per-week'][0], feature_ranges_0['hours-per-week'][1]))\n",
    "]\n",
    "\n",
    "# Filter class 1\n",
    "filtered_class_1_with_y = df_num[(df_num['target'] == 1) &\n",
    "    (df_num['age'].between(feature_ranges_1['age'][0], feature_ranges_1['age'][1])) &\n",
    "    (df_num['fnlwgt'].between(feature_ranges_1['fnlwgt'][0], feature_ranges_1['fnlwgt'][1])) &\n",
    "    (df_num['capital-gain'].between(feature_ranges_1['capital-gain'][0], feature_ranges_1['capital-gain'][1])) &\n",
    "    (df_num['capital-loss'].between(feature_ranges_1['capital-loss'][0], feature_ranges_1['capital-loss'][1])) &\n",
    "    (df_num['hours-per-week'].between(feature_ranges_1['hours-per-week'][0], feature_ranges_1['hours-per-week'][1]))\n",
    "]\n",
    "\n",
    "\n",
    "print(filtered_class_0_with_y)\n",
    "print(filtered_class_1_with_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Voting Accuracy: 0.688\n",
      "Hard Voting Accuracy: 0.688\n"
     ]
    }
   ],
   "source": [
    "iterations = 500\n",
    "\n",
    "all_predicted_probabilities = []\n",
    "\n",
    "for i in range(iterations):\n",
    "    \n",
    "    additional_samples_class_0 = df_num[(df_num['target'] == 0) & \n",
    "                                               (~df_num.index.isin(filtered_class_0_with_y.index))].sample(n=500)\n",
    "    \n",
    "    additional_samples_class_1 = df_num[(df_num['target'] == 1) & \n",
    "                                               (~df_num.index.isin(filtered_class_1_with_y.index))].sample(n=500)\n",
    "    \n",
    "    # Combine selected instances\n",
    "    combined_df = pd.concat([filtered_class_0_with_y, filtered_class_1_with_y, additional_samples_class_0, additional_samples_class_1])\n",
    "    \n",
    "    X = combined_df.drop(columns=['target'])\n",
    "    y = combined_df['target']\n",
    "    \n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(X, y)\n",
    "    proba = clf.predict_proba(df_X_test1)\n",
    "    \n",
    "    all_predicted_probabilities.append(proba)\n",
    "\n",
    "soft_voting_predictions = np.mean(all_predicted_probabilities, axis=0)\n",
    "\n",
    "soft_voting_accuracy = accuracy_score(df_y_test1, np.argmax(soft_voting_predictions, axis=1))\n",
    "\n",
    "print(\"Soft Voting Accuracy:\", soft_voting_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.667432\n",
      "Soft Voting Accuracy: 0.6796666666666666\n",
      "Hard Voting Accuracy: 0.6796666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Bootstrap\n",
    "\n",
    "n_bootstraps = 500\n",
    "\n",
    "accuracy_scores = []\n",
    "all_predicted_probabilities = []\n",
    "\n",
    "for i in range(n_bootstraps):\n",
    "    X_train_bootstrap, y_train_bootstrap = resample(X, y, replace=True, random_state=i)\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train_bootstrap, y_train_bootstrap)\n",
    "    \n",
    "    y_pred = model.predict(df_X_test1)\n",
    "\n",
    "    all_predicted_probabilities.append(model.predict_proba(df_X_test1))\n",
    "    \n",
    "    accuracy = accuracy_score(df_y_test1, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "print(\"Mean Accuracy:\", mean_accuracy)\n",
    "\n",
    "soft_voting_predictions = np.mean(all_predicted_probabilities, axis=0)\n",
    "soft_voting_accuracy = accuracy_score(df_y_test1, np.argmax(soft_voting_predictions, axis=1))\n",
    "print(\"Soft Voting Accuracy:\", soft_voting_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6686666666666666\n"
     ]
    }
   ],
   "source": [
    "# Single random forest\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X, y)\n",
    "\n",
    "y_pred = model.predict(df_X_test1)\n",
    "\n",
    "accuracy = accuracy_score(df_y_test1, y_pred)\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
