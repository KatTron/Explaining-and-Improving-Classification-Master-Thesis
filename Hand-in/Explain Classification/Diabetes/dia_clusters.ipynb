{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import hdbscan\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import numpy as np\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'diabetes_prediction_dataset.csv'  \n",
    "df = pd.read_csv(file_path)\n",
    "data = df.copy()\n",
    "data=data.dropna()\n",
    "\n",
    "numeric_columns = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
    "numeric_data = data[numeric_columns]\n",
    "\n",
    "#Scaling\n",
    "scaler = MinMaxScaler()\n",
    "scaled_data = scaler.fit_transform(numeric_data)\n",
    "scaled_df = pd.DataFrame(scaled_data, columns=numeric_columns)\n",
    "result_data = pd.concat([data.drop(columns=numeric_columns), scaled_df], axis=1)\n",
    "\n",
    "#Subsample\n",
    "num_samples_per_class = 5000\n",
    "diabetes_class_0 = result_data[result_data['diabetes'] == 0].sample(n=num_samples_per_class, random_state=42)\n",
    "diabetes_class_1 = result_data[result_data['diabetes'] == 1].sample(n=num_samples_per_class, random_state=42)\n",
    "random_sample = pd.concat([diabetes_class_0, diabetes_class_1], axis=0)\n",
    "random_sample = random_sample.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = random_sample[['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']]\n",
    "y = random_sample['diabetes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a dict for each feature with value count and safe as csv for whole subset\n",
    "\n",
    "def create_unique_count_df(column_name):\n",
    "    if column_name not in X.columns:\n",
    "        print(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame\n",
    "    unique_values = X[column_name].unique()\n",
    "    value_counts = X[column_name].value_counts()\n",
    "    unique_count_df = pd.DataFrame({'Value': unique_values, 'Count': value_counts})\n",
    "    return unique_count_df\n",
    "\n",
    "\n",
    "columns = X.columns\n",
    "unique_values_counts_dict = {}\n",
    "\n",
    "for col in columns:\n",
    "    unique_count_df = create_unique_count_df(col)\n",
    "    unique_values_counts_dict[col] = unique_count_df\n",
    "\n",
    "# Save each dict for each feature to separate csv files\n",
    "for col, df_count in unique_values_counts_dict.items():\n",
    "    csv_file_name = f\"{col}_unique_values_counts.csv\"\n",
    "    df_count.to_csv(csv_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Interval  Count\n",
      "0   (0.0, 0.05]     56\n",
      "1   (0.05, 0.1]    610\n",
      "2   (0.1, 0.15]    947\n",
      "3   (0.15, 0.2]   3555\n",
      "4   (0.2, 0.25]   1447\n",
      "5   (0.25, 0.3]   1162\n",
      "6   (0.3, 0.35]    908\n",
      "7   (0.35, 0.4]    575\n",
      "8   (0.4, 0.45]    387\n",
      "9   (0.45, 0.5]    197\n",
      "10  (0.5, 0.55]     83\n",
      "11  (0.55, 0.6]     39\n",
      "12  (0.6, 0.65]     14\n",
      "13  (0.65, 0.7]     12\n",
      "14  (0.7, 0.75]      4\n",
      "15  (0.75, 0.8]      0\n",
      "16  (0.8, 0.85]      2\n",
      "17  (0.85, 0.9]      1\n",
      "18  (0.9, 0.95]      1\n",
      "19  (0.95, 1.0]      0\n"
     ]
    }
   ],
   "source": [
    "file_path = 'bmi_unique_values_counts.csv'  # read one feature file \n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "# Define bins for the intervals\n",
    "bins = [0.00, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1.00]\n",
    "\n",
    "# Create intervals and sum 'Count' values within each interval\n",
    "df['Interval'] = pd.cut(df['Value'], bins=bins, include_lowest=False)\n",
    "result_df = df.groupby('Interval')['Count'].sum().reset_index()\n",
    "\n",
    "print(result_df)\n",
    "\n",
    "# Save result in a csv file\n",
    "result_df.to_csv(\"bmi_all.csv\", index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "       Interval  Count\n",
      "0   (0.0, 0.05]    269\n",
      "1   (0.05, 0.1]    184\n",
      "2   (0.1, 0.15]    182\n",
      "3   (0.15, 0.2]    247\n",
      "4   (0.2, 0.25]    270\n",
      "5   (0.25, 0.3]    282\n",
      "6   (0.3, 0.35]    314\n",
      "7   (0.35, 0.4]    369\n",
      "8   (0.4, 0.45]    397\n",
      "9   (0.45, 0.5]    498\n",
      "10  (0.5, 0.55]    457\n",
      "11  (0.55, 0.6]    574\n",
      "12  (0.6, 0.65]    663\n",
      "13  (0.65, 0.7]    692\n",
      "14  (0.7, 0.75]    832\n",
      "15  (0.75, 0.8]    749\n",
      "16  (0.8, 0.85]    722\n",
      "17  (0.85, 0.9]    589\n",
      "18  (0.9, 0.95]    532\n",
      "19  (0.95, 1.0]   1176\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000012C604270D0>\n",
      "bmi\n",
      "       Interval  Count\n",
      "0   (0.0, 0.05]     33\n",
      "1   (0.05, 0.1]    436\n",
      "2   (0.1, 0.15]    905\n",
      "3   (0.15, 0.2]   1621\n",
      "4   (0.2, 0.25]   4026\n",
      "5   (0.25, 0.3]   1295\n",
      "6   (0.3, 0.35]    796\n",
      "7   (0.35, 0.4]    429\n",
      "8   (0.4, 0.45]    234\n",
      "9   (0.45, 0.5]    119\n",
      "10  (0.5, 0.55]     53\n",
      "11  (0.55, 0.6]     30\n",
      "12  (0.6, 0.65]      9\n",
      "13  (0.65, 0.7]      8\n",
      "14  (0.7, 0.75]      2\n",
      "15  (0.75, 0.8]      0\n",
      "16  (0.8, 0.85]      2\n",
      "17  (0.85, 0.9]      1\n",
      "18  (0.9, 0.95]      1\n",
      "19  (0.95, 1.0]      0\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000012C60427550>\n",
      "HbA1c_level\n",
      "       Interval  Count\n",
      "0   (0.0, 0.05]      0\n",
      "1   (0.05, 0.1]    395\n",
      "2   (0.1, 0.15]      0\n",
      "3   (0.15, 0.2]    419\n",
      "4   (0.2, 0.25]    422\n",
      "5   (0.25, 0.3]    381\n",
      "6   (0.3, 0.35]      0\n",
      "7   (0.35, 0.4]    811\n",
      "8   (0.4, 0.45]    840\n",
      "9   (0.45, 0.5]   2369\n",
      "10  (0.5, 0.55]    768\n",
      "11  (0.55, 0.6]   1216\n",
      "12  (0.6, 0.65]    363\n",
      "13  (0.65, 0.7]      0\n",
      "14  (0.7, 0.75]    378\n",
      "15  (0.75, 0.8]      0\n",
      "16  (0.8, 0.85]      0\n",
      "17  (0.85, 0.9]    403\n",
      "18  (0.9, 0.95]      0\n",
      "19  (0.95, 1.0]    794\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000012C6046E730>\n",
      "blood_glucose_level\n",
      "       Interval  Count\n",
      "0   (0.0, 0.05]    759\n",
      "1   (0.05, 0.1]    392\n",
      "2   (0.1, 0.15]      0\n",
      "3   (0.15, 0.2]      0\n",
      "4   (0.2, 0.25]   1577\n",
      "5   (0.25, 0.3]   1517\n",
      "6   (0.3, 0.35]    684\n",
      "7   (0.35, 0.4]   2038\n",
      "8   (0.4, 0.45]      0\n",
      "9   (0.45, 0.5]      0\n",
      "10  (0.5, 0.55]    714\n",
      "11  (0.55, 0.6]      0\n",
      "12  (0.6, 0.65]    350\n",
      "13  (0.65, 0.7]      0\n",
      "14  (0.7, 0.75]    387\n",
      "15  (0.75, 0.8]      0\n",
      "16  (0.8, 0.85]    377\n",
      "17  (0.85, 0.9]      0\n",
      "18  (0.9, 0.95]    427\n",
      "19  (0.95, 1.0]    401\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000012C6046E6A0>\n"
     ]
    }
   ],
   "source": [
    "# print the feature value ranges with iterations\n",
    "\n",
    "list = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
    "\n",
    "for l in list:\n",
    "    print(l)\n",
    "    #file_path = 'age_unique_values_counts.csv'  \n",
    "    df = X[l].copy()\n",
    "    df = pd.DataFrame(df)\n",
    "\n",
    "    bins = [0.00, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1.00]\n",
    "\n",
    "    df['Interval'] = pd.cut(df[l], bins=bins, include_lowest=False)\n",
    "\n",
    "    bin_counts = df.groupby('Interval').size().reset_index(name='Count')\n",
    "\n",
    "    bin_counts['Interval'] = bin_counts['Interval'].astype(str)\n",
    "    bin_counts = bin_counts.sort_values(by='Interval')\n",
    "\n",
    "    print(bin_counts)\n",
    "\n",
    "    ordered_df = df.groupby('Interval')\n",
    "    print(ordered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Purity for 3 clusters: 0.83\n",
      "0, 0.92, 3291, 3035/256\n",
      "1, 0.99, 2152, 22/2130\n",
      "2, 0.57, 4557, 1943/2614\n",
      "Overall Purity for 4 clusters: 0.89\n",
      "0, 0.91, 2573, 2330/243\n",
      "1, 0.67, 4013, 1305/2708\n",
      "2, 0.99, 1379, 1364/15\n",
      "3, 1.00, 2035, 1/2034\n",
      "Overall Purity for 5 clusters: 0.89\n",
      "0, 0.91, 2461, 2247/214\n",
      "1, 0.56, 3387, 1498/1889\n",
      "2, 1.00, 1255, 1255/0\n",
      "3, 1.00, 1091, 0/1091\n",
      "4, 1.00, 1806, 0/1806\n",
      "Overall Purity for 6 clusters: 0.86\n",
      "0, 0.96, 1639, 1579/60\n",
      "1, 0.60, 2277, 914/1363\n",
      "2, 1.00, 1240, 1240/0\n",
      "3, 1.00, 998, 0/998\n",
      "4, 1.00, 1810, 3/1807\n",
      "5, 0.62, 2036, 1264/772\n",
      "Overall Purity for 7 clusters: 0.88\n",
      "0, 0.96, 1631, 1572/59\n",
      "1, 0.59, 2195, 896/1299\n",
      "2, 1.00, 1239, 1239/0\n",
      "3, 1.00, 877, 0/877\n",
      "4, 1.00, 593, 0/593\n",
      "5, 0.63, 1990, 1256/734\n",
      "6, 0.97, 1475, 37/1438\n",
      "Overall Purity for 8 clusters: 0.89\n",
      "0, 1.00, 1012, 1012/0\n",
      "1, 0.64, 1951, 702/1249\n",
      "2, 1.00, 932, 932/0\n",
      "3, 1.00, 591, 0/591\n",
      "4, 0.98, 1455, 32/1423\n",
      "5, 0.61, 1973, 1199/774\n",
      "6, 1.00, 852, 0/852\n",
      "7, 0.91, 1234, 1123/111\n",
      "Overall Purity for 9 clusters: 0.89\n",
      "0, 1.00, 950, 950/0\n",
      "1, 0.65, 1839, 635/1204\n",
      "2, 0.96, 771, 738/33\n",
      "3, 1.00, 590, 0/590\n",
      "4, 1.00, 1310, 0/1310\n",
      "5, 0.53, 1694, 793/901\n",
      "6, 1.00, 845, 0/845\n",
      "7, 0.90, 1115, 998/117\n",
      "8, 1.00, 886, 886/0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Use a K-Means clustering algorithm to partitioning data and calculate purity and counts for each cluster\n",
    "\n",
    "number_clusters = [3, 4, 5, 6, 7, 8, 9]\n",
    "\n",
    "for n in number_clusters:\n",
    "    kmeans = KMeans(n_clusters=n, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(X)\n",
    "\n",
    "    X_n = random_sample[['age', 'bmi', 'HbA1c_level', 'blood_glucose_level', 'diabetes']].copy()\n",
    "    X_n['cluster'] = cluster_labels\n",
    "\n",
    "    print(f\"Number of clusters: {n}\")\n",
    "\n",
    "    # Class count for cluster\n",
    "    for cluster in range(n):\n",
    "        cluster_data = X_n[X_n['cluster'] == cluster]\n",
    "        total_in_cluster = len(cluster_data)\n",
    "        class_0_in_cluster = len(cluster_data[cluster_data['diabetes'] == 0])\n",
    "        class_1_in_cluster = len(cluster_data[cluster_data['diabetes'] == 1])\n",
    "        \n",
    "        # Calculate purity score for the current cluster\n",
    "        if total_in_cluster > 0:\n",
    "            majority_class = cluster_data['diabetes'].mode()[0]\n",
    "            correct_predictions = len(cluster_data[cluster_data['diabetes'] == majority_class])\n",
    "            cluster_purity_score = correct_predictions / total_in_cluster\n",
    "        else:\n",
    "            cluster_purity_score = 0\n",
    "\n",
    "        print(f\"Cluster {cluster}:\")\n",
    "        print(f\"  Total observations: {total_in_cluster}\")\n",
    "        print(f\"  Observations in class 0: {class_0_in_cluster}\")\n",
    "        print(f\"  Observations in class 1: {class_1_in_cluster}\")\n",
    "        print(f\"  Purity score: {cluster_purity_score:.2f}\")\n",
    "\n",
    "    # Calculate overall purity score\n",
    "    purity_scores = []\n",
    "    for cluster in range(n):\n",
    "        cluster_data = X_n[X_n['cluster'] == cluster]\n",
    "        if len(cluster_data) > 0:\n",
    "            majority_class = cluster_data['diabetes'].mode()[0]\n",
    "            correct_predictions = len(cluster_data[cluster_data['diabetes'] == majority_class])\n",
    "            purity_scores.append(correct_predictions / len(cluster_data))\n",
    "    \n",
    "    overall_purity_score = sum(purity_scores) / n\n",
    "    print(f\"Overall purity score: {overall_purity_score:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           age       bmi  HbA1c_level  blood_glucose_level  cluster\n",
      "0     1.000000  0.191293     0.854545             0.209091        3\n",
      "1     0.161662  0.241713     0.472727             0.354545        0\n",
      "2     0.061562  0.202031     0.490909             0.000000        0\n",
      "3     0.587087  0.418651     0.090909             0.359091        2\n",
      "4     0.324324  0.202031     0.454545             0.227273        0\n",
      "...        ...       ...          ...                  ...      ...\n",
      "9995  0.712212  0.270775     0.854545             0.340909        3\n",
      "9996  0.662162  0.202031     0.472727             1.000000        4\n",
      "9997  0.436937  0.327848     0.854545             0.295455        3\n",
      "9998  0.324324  0.202031     0.545455             0.000000        0\n",
      "9999  0.699700  0.202031     0.418182             0.545455        1\n",
      "\n",
      "[10000 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# The selected partitioning\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)\n",
    "cluster_labels = kmeans.fit_predict(X)\n",
    "\n",
    "X_5 = X.copy()\n",
    "X_5['cluster'] = cluster_labels\n",
    "print(X_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3387\n"
     ]
    }
   ],
   "source": [
    "# Save a df with all clusters in partitioning\n",
    "\n",
    "cluster_0_df = X_5[X_5['cluster'] == 0][['age', 'bmi', 'blood_glucose_level', 'HbA1c_level']]\n",
    "cluster_1_df = X_5[X_5['cluster'] == 1][['age', 'bmi', 'blood_glucose_level', 'HbA1c_level']]\n",
    "cluster_2_df = X_5[X_5['cluster'] == 2][['age', 'bmi', 'blood_glucose_level', 'HbA1c_level']]\n",
    "cluster_3_df = X_5[X_5['cluster'] == 3][['age', 'bmi', 'blood_glucose_level', 'HbA1c_level']]\n",
    "cluster_4_df = X_5[X_5['cluster'] == 4][['age', 'bmi', 'blood_glucose_level', 'HbA1c_level']]\n",
    "\n",
    "print(len(cluster_1_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create a dict with unique values and their counts\n",
    "def create_unique_count_df(column_name):\n",
    "    if column_name not in cluster_1_df.columns:\n",
    "        print(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "        return pd.DataFrame()  # Return an empty DataFrame\n",
    "    unique_values = cluster_1_df[column_name].unique()\n",
    "    value_counts = cluster_1_df[column_name].value_counts()\n",
    "    unique_count_df = pd.DataFrame({'Value': unique_values, 'Count': value_counts})\n",
    "    return unique_count_df\n",
    "\n",
    "columns = cluster_1_df.columns\n",
    "unique_values_counts_dict = {}\n",
    "\n",
    "# Iterate over each feature, and store it in the dictionary\n",
    "for col in columns:\n",
    "    unique_count_df = create_unique_count_df(col)\n",
    "    unique_values_counts_dict[col] = unique_count_df\n",
    "\n",
    "# Save each df for each feature to separate csv files\n",
    "for col, df_count in unique_values_counts_dict.items():\n",
    "    csv_file_name = f\"{col}_unique_values_counts.csv\"\n",
    "    df_count.to_csv(csv_file_name, index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age\n",
      "       Interval  Count\n",
      "0   (0.0, 0.05]      0\n",
      "1   (0.05, 0.1]      0\n",
      "2   (0.1, 0.15]      0\n",
      "3   (0.15, 0.2]      0\n",
      "4   (0.2, 0.25]      0\n",
      "5   (0.25, 0.3]      0\n",
      "6   (0.3, 0.35]      0\n",
      "7   (0.35, 0.4]      0\n",
      "8   (0.4, 0.45]      1\n",
      "9   (0.45, 0.5]     35\n",
      "10  (0.5, 0.55]    198\n",
      "11  (0.55, 0.6]    286\n",
      "12  (0.6, 0.65]    310\n",
      "13  (0.65, 0.7]    331\n",
      "14  (0.7, 0.75]    388\n",
      "15  (0.75, 0.8]    358\n",
      "16  (0.8, 0.85]    330\n",
      "17  (0.85, 0.9]    291\n",
      "18  (0.9, 0.95]    272\n",
      "19  (0.95, 1.0]    587\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000012C6046E760>\n",
      "bmi\n",
      "       Interval  Count\n",
      "0   (0.0, 0.05]      1\n",
      "1   (0.05, 0.1]     28\n",
      "2   (0.1, 0.15]    205\n",
      "3   (0.15, 0.2]    557\n",
      "4   (0.2, 0.25]   1476\n",
      "5   (0.25, 0.3]    497\n",
      "6   (0.3, 0.35]    280\n",
      "7   (0.35, 0.4]    175\n",
      "8   (0.4, 0.45]     88\n",
      "9   (0.45, 0.5]     44\n",
      "10  (0.5, 0.55]     19\n",
      "11  (0.55, 0.6]      9\n",
      "12  (0.6, 0.65]      2\n",
      "13  (0.65, 0.7]      3\n",
      "14  (0.7, 0.75]      1\n",
      "15  (0.75, 0.8]      0\n",
      "16  (0.8, 0.85]      1\n",
      "17  (0.85, 0.9]      1\n",
      "18  (0.9, 0.95]      0\n",
      "19  (0.95, 1.0]      0\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000012C604CEFD0>\n",
      "HbA1c_level\n",
      "       Interval  Count\n",
      "0   (0.0, 0.05]      0\n",
      "1   (0.05, 0.1]      0\n",
      "2   (0.1, 0.15]      0\n",
      "3   (0.15, 0.2]      1\n",
      "4   (0.2, 0.25]     41\n",
      "5   (0.25, 0.3]     55\n",
      "6   (0.3, 0.35]      0\n",
      "7   (0.35, 0.4]    421\n",
      "8   (0.4, 0.45]    407\n",
      "9   (0.45, 0.5]   1223\n",
      "10  (0.5, 0.55]    412\n",
      "11  (0.55, 0.6]    643\n",
      "12  (0.6, 0.65]    184\n",
      "13  (0.65, 0.7]      0\n",
      "14  (0.7, 0.75]      0\n",
      "15  (0.75, 0.8]      0\n",
      "16  (0.8, 0.85]      0\n",
      "17  (0.85, 0.9]      0\n",
      "18  (0.9, 0.95]      0\n",
      "19  (0.95, 1.0]      0\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000012C6046E820>\n",
      "blood_glucose_level\n",
      "       Interval  Count\n",
      "0   (0.0, 0.05]    196\n",
      "1   (0.05, 0.1]    107\n",
      "2   (0.1, 0.15]      0\n",
      "3   (0.15, 0.2]      0\n",
      "4   (0.2, 0.25]    713\n",
      "5   (0.25, 0.3]    741\n",
      "6   (0.3, 0.35]    322\n",
      "7   (0.35, 0.4]    849\n",
      "8   (0.4, 0.45]      0\n",
      "9   (0.45, 0.5]      0\n",
      "10  (0.5, 0.55]    353\n",
      "11  (0.55, 0.6]      0\n",
      "12  (0.6, 0.65]      0\n",
      "13  (0.65, 0.7]      0\n",
      "14  (0.7, 0.75]      0\n",
      "15  (0.75, 0.8]      0\n",
      "16  (0.8, 0.85]      0\n",
      "17  (0.85, 0.9]      0\n",
      "18  (0.9, 0.95]      0\n",
      "19  (0.95, 1.0]      0\n",
      "<pandas.core.groupby.generic.DataFrameGroupBy object at 0x0000012C5FFEC160>\n"
     ]
    }
   ],
   "source": [
    "# function to print all feature distributions \n",
    "list = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']\n",
    "\n",
    "for l in list:\n",
    "    print(l)\n",
    "    #file_path = 'age_unique_values_counts.csv'  \n",
    "    df = cluster_1_df[l].copy()\n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(df)\n",
    "\n",
    "    # Define bins for the intervals\n",
    "    bins = [0.00, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95, 1.00]\n",
    "\n",
    "    # Create intervals and sum 'Count' values within each interval\n",
    "    df['Interval'] = pd.cut(df[l], bins=bins, include_lowest=False)\n",
    "\n",
    "    # Group by 'Interval' and count the number of occurrences\n",
    "    bin_counts = df.groupby('Interval').size().reset_index(name='Count')\n",
    "\n",
    "    # Sort bins by interval\n",
    "    bin_counts['Interval'] = bin_counts['Interval'].astype(str)\n",
    "    bin_counts = bin_counts.sort_values(by='Interval')\n",
    "\n",
    "    print(bin_counts)\n",
    "\n",
    "    ordered_df = df.groupby('Interval')\n",
    "    print(ordered_df)\n",
    "#result_df = df.groupby('Interval')['Count'].sum().reset_index()\n",
    "\n",
    "#print(result_df)\n",
    "\n",
    "#result_df.to_csv(\"age_bins.csv\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'bmi_unique_values_counts.csv'  \n",
    "df = pd.read_csv(file_path)\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "# Define bins for the intervals\n",
    "bins = [0.00, 0.05, 0.10, 0.15, 0.20, 0.25, 0.30, 0.35, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90]\n",
    "\n",
    "# Create intervals and sum 'Count' values within each interval\n",
    "df['Interval'] = pd.cut(df['Value'], bins=bins, right=False, include_lowest=True)\n",
    "result_df = df.groupby('Interval')['Count'].sum().reset_index()\n",
    "\n",
    "print(result_df)\n",
    "\n",
    "result_df.to_csv(\"bmi_bins.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(cluster_labels))\n",
    "print(type(y))\n",
    "y_array = y.values\n",
    "print(type(y_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_overlap = pd.concat([pd.DataFrame(X, columns=X.columns), pd.DataFrame(cluster_labels, columns=['Clusters']), pd.DataFrame(y_array, columns=['Class'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = df_overlap[df_overlap['Clusters'] == 1].copy()\n",
    "grouped = measure.groupby('Class')\n",
    "\n",
    "# Create an empty dictionary to store the mean and standard deviation for each feature\n",
    "stats_dict = {}\n",
    "\n",
    "# Iterate over each group\n",
    "for group_name, group_df in grouped:\n",
    "    # Calculate the mean and standard deviation for each column in the group\n",
    "    mean_values = group_df.mean()\n",
    "    std_values = group_df.std()\n",
    "    \n",
    "    # Store mean and std in a dictionary for each feature\n",
    "    for feature in group_df.columns:\n",
    "        if feature not in stats_dict:\n",
    "            stats_dict[feature] = {}\n",
    "        \n",
    "        stats_dict[feature]['mean_' + str(group_name)] = mean_values[feature]\n",
    "        stats_dict[feature]['std_' + str(group_name)] = std_values[feature]\n",
    "\n",
    "# Display the dictionary\n",
    "print(stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'feature_to_delete' is the feature you want to delete\n",
    "feature_to_delete = 'Class'\n",
    "\n",
    "# Check if the feature exists in stats_dict before deleting\n",
    "if feature_to_delete in stats_dict:\n",
    "    del stats_dict[feature_to_delete]\n",
    "    print(f\"{feature_to_delete} deleted from stats_dict\")\n",
    "else:\n",
    "    print(f\"{feature_to_delete} does not exist in stats_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume 'feature_to_delete' is the feature you want to delete\n",
    "feature_to_delete = 'Clusters'\n",
    "\n",
    "# Check if the feature exists in stats_dict before deleting\n",
    "if feature_to_delete in stats_dict:\n",
    "    del stats_dict[feature_to_delete]\n",
    "    print(f\"{feature_to_delete} deleted from stats_dict\")\n",
    "else:\n",
    "    print(f\"{feature_to_delete} does not exist in stats_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store the rf_i value for each feature\n",
    "rf_dict = {}\n",
    "\n",
    "# Iterate over each feature in stats_dict\n",
    "for feature, stats_values in stats_dict.items():\n",
    "    # Calculate rf_i value using the provided formula\n",
    "    rf_i = ((stats_values['mean_0'] - stats_values['mean_1'])**2) / (stats_values['std_0']**2 + stats_values['std_1']**2)\n",
    "    \n",
    "    # Store rf_i value in rf_dict\n",
    "    rf_dict[feature] = rf_i\n",
    "\n",
    "# Display the dictionary with rf values\n",
    "print(rf_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
