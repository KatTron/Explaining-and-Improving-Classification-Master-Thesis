{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import hdbscan\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import numpy as np\n",
    "from sklearn.metrics.cluster import contingency_matrix\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "from sklearn.metrics import pairwise_distances_argmin_min\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "adult = fetch_ucirepo(id=2) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets \n",
    "\n",
    "df = X.copy()\n",
    "df['y'] = y\n",
    " \n",
    "df=df.dropna()\n",
    "\n",
    "df['target'] = df['y'].map({'<=50K': 0, '<=50K.': 0, '>50K': 1, '>50K.': 1})\n",
    "df = df.drop('y', axis=1)\n",
    "\n",
    "df_num = df[['age', 'fnlwgt', 'capital-gain', 'capital-loss', 'hours-per-week', 'target']]\n",
    "\n",
    "def sample_from_group(group):\n",
    "    return group.sample(min(len(group), 5000), random_state=42)\n",
    "\n",
    "sampled_df = df_num.groupby('target', group_keys=False).apply(sample_from_group)\n",
    "sampled_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_num_scaled = scaler.fit_transform(sampled_df)\n",
    "\n",
    "df_num = pd.DataFrame(df_num_scaled, columns=df_num.columns)\n",
    "\n",
    "target_counts = df_num['target'].value_counts()\n",
    "print(target_counts)\n",
    "\n",
    "num_observations = df_num.shape[0]\n",
    "print(\"Number of Observations:\", num_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "measure = df_num.copy()\n",
    "grouped = measure.groupby('target')\n",
    "\n",
    "stats_dict = {}\n",
    "\n",
    "# Iterate over each class\n",
    "for group_name, group_df in grouped:\n",
    "    # Calculate the mean and standard deviation for each column in the class\n",
    "    mean_values = group_df.mean()\n",
    "    std_values = group_df.std()\n",
    "    \n",
    "    # Store mean and std in a dictionary for each feature\n",
    "    for feature in group_df.columns:\n",
    "        if feature not in stats_dict:\n",
    "            stats_dict[feature] = {}\n",
    "        \n",
    "        stats_dict[feature]['mean_' + str(group_name)] = mean_values[feature]\n",
    "        stats_dict[feature]['std_' + str(group_name)] = std_values[feature]\n",
    "\n",
    "print(stats_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_to_delete = 'target'\n",
    "\n",
    "if feature_to_delete in stats_dict:\n",
    "    del stats_dict[feature_to_delete]\n",
    "    print(f\"{feature_to_delete} deleted from stats_dict\")\n",
    "else:\n",
    "    print(f\"{feature_to_delete} does not exist in stats_dict\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_dict = {}\n",
    "\n",
    "# Iterate over each feature in stats_dict\n",
    "for feature, stats_values in stats_dict.items():\n",
    "    # Calculate rf_i value using the f1 formula\n",
    "    rf_i = ((stats_values['mean_0.0'] - stats_values['mean_1.0'])**2) / (stats_values['std_0.0']**2 + stats_values['std_1.0']**2)\n",
    "    rf_dict[feature] = rf_i\n",
    "\n",
    "print(rf_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inverse f1 score\n",
    "f1_overlap = 1/(1+0.18492082592324244)   #max value in rf_dict\n",
    "print(f1_overlap)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
